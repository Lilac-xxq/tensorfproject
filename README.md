# tensorfproject

本项目参考自github上一个名为TensoRF的开源项目，仓库地址为：https://github.com/apchenstu/TensoRF

本项目的重点在于对身边某物体进行拍照拍视频取材，然后利用该项目对该物体进行3D重建，生成新视角下的视频。

本项目的工作量集中在：
  1. 拍摄获取数据集并colmap处理（my_data/lego_dino）成transform.json
  2. 为我的数据集设计接入模型的dataloader（dataloader/llff_json.py）
  3. 设计渲染新视角的轨道和aabb空间（dataloader/llff_json.py），保证渲染结果可见

项目中曾经遇到的问题及解决办法：
  1. final新视角渲染鬼影问题-调整新轨迹生成方式
     - 原项目中生成新视角的路径是将训练集数据的位置进行中心化处理，再基于此生成螺旋状的新轨迹曲线（可参考本仓库中的Figure_1.png）。
     - ![Figure_1](https://github.com/user-attachments/assets/c4b4166f-0779-4fcc-a827-2f40150edca2)
     - 但该中心化得到的绿点与本项目的数据集视角（蓝点）偏离较远，导致螺旋轨迹新曲线（红线）偏离更远。对于与原数据集偏离过远的新视角，训练好的模型能给出的推理准确性有限，导致生成的渲染结果中形成大量纯白和鬼影情况。
     - 经检查，原项目中先中心化再生成螺旋线的方式适用于有很多专业设备围绕物体进行全方位拍摄采集数据的方式，方便定位物体中心位置，但本项目所采用的数据集是手持相机围绕物体拍摄一圈获取，并不适用这种新轨迹生成方式。
     - 因而对原项目的新轨迹生成方式做了调整，围绕训练集数据所在位置附近生成一圈新视角（已经体现在dataloader/llff_json.py）。
     - 同时，原项目使用的aabb框是根据中心化后的绿点规划的，如果轨迹圈过大而aabb过小，渲染效果会像是在一个盒子外观察盒子旋转，而非在盒子内观察物体。因而对aabb也进行调整使其依据训练数据集（蓝点）生成并进行适当的上下扩展（洋红色方框），同时调小新轨迹圈（橙黄线）保证视野。
     - ![Figure_2](https://github.com/user-attachments/assets/0d4a5bbb-0b73-4dac-a8a5-3115f0f7b085)
     - 新轨迹路线可利用renderpathvisdebug.py进行可视化观察确认。
  2. final渲染环节OOM
     - 新视角渲染由于处理单张图片的压力极大，经常遇到OOM,在实际train过程中未能与模型的训练测试环节一起完成，遂采用了分批次渲染的操作方法，即调用训练保存好的模型单独进行渲染环节。
     - 分批次渲染涉及了对原项目代码文件的一些改造，具体可参见TensoRF ver_onlyrender文件夹。
  3. 其他补充
     - 仓库中的run_cpu_test.py可在cpu环境进行快速测试，确认整个项目跑通、输出产物正常。确认项目流程通常后方便进行完整训练与渲染。

